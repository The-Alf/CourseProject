# dags/cbr_currency_loader.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from datetime import datetime, timedelta
import requests
import xml.etree.ElementTree as ET
import logging

logger = logging.getLogger(__name__)

def create_currencies_table():
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ĞºÑƒÑ€ÑĞ¾Ğ² Ğ²Ğ°Ğ»ÑÑ‚"""
    hook = PostgresHook(postgres_conn_id='postgresql982')
    
    create_table_sql = """
    CREATE TABLE IF NOT EXISTS analytics.currencies_history (
        id SERIAL PRIMARY KEY,
        currency VARCHAR(10) NOT NULL,
        value DECIMAL(10, 4) NOT NULL,
        val_date DATE NOT NULL,
        sysdate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(currency, val_date)
    );
    
    CREATE INDEX IF NOT EXISTS idx_currencies_history_currency 
    ON analytics.currencies_history(currency);
    
    CREATE INDEX IF NOT EXISTS idx_currencies_history_date 
    ON analytics.currencies_history(val_date);
    
    CREATE INDEX IF NOT EXISTS idx_currencies_history_currency_date 
    ON analytics.currencies_history(currency, val_date);
    """
    
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑÑ…ĞµĞ¼Ñƒ analytics ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
        hook.run("CREATE SCHEMA IF NOT EXISTS analytics;")
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ
        hook.run(create_table_sql)
        logger.info("âœ… Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° analytics.currencies_history ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°/Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ°")
        return "Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°/Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾"
        
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹: {e}")
        raise

def check_if_first_run():
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº (Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¿ÑƒÑÑ‚Ğ°Ñ)"""
    hook = PostgresHook(postgres_conn_id='postgresql982')
    
    check_sql = """
    SELECT COUNT(*) as record_count 
    FROM analytics.currencies_history;
    """
    
    try:
        result = hook.get_first(check_sql)
        record_count = result[0] if result else 0
        
        is_first_run = record_count == 0
        logger.info(f"ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ: {record_count}. ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº: {is_first_run}")
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² XCom Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…
        return is_first_run
        
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹: {e}")
        # Ğ•ÑĞ»Ğ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ½ĞµÑ‚, ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº
        return True

def parse_cbr_xml(xml_content, currency_code):
    """ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ XML Ğ¾Ñ‚ Ğ¦Ğ‘ Ğ Ğ¤ Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ ĞºÑƒÑ€ÑĞ°Ñ…"""
    try:
        root = ET.fromstring(xml_content)
        records = []
        
        # ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ ĞºĞ¾Ğ´Ğ¾Ğ² Ğ²Ğ°Ğ»ÑÑ‚ Ğ¦Ğ‘ Ğ½Ğ° ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹
        currency_map = {
            'R01235': 'USD',
            'R01239': 'EUR', 
            'R01035': 'GBP',
            'R01375': 'CNY'
        }
        
        currency_name = currency_map.get(currency_code, currency_code)
        
        for record in root.findall('Record'):
            date_str = record.get('Date')
            value_str = record.find('Value').text.replace(',', '.')
            
            # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ°Ñ‚Ñƒ Ğ¸Ğ· Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° Ğ¦Ğ‘ (Ğ´Ğ´.Ğ¼Ğ¼.Ğ³Ğ³Ğ³Ğ³)
            date_obj = datetime.strptime(date_str, '%d.%m.%Y').date()
            value = float(value_str)
            
            records.append({
                'currency': currency_name,
                'value': value,
                'val_date': date_obj
            })
        
        logger.info(f"âœ… Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¾ {len(records)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ´Ğ»Ñ {currency_name}")
        return records
        
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° XML Ğ´Ğ»Ñ {currency_code}: {e}")
        raise

def load_historical_data():
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ° Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ 2020-2025"""
    currencies = {
        'USD': 'R01235',
        'EUR': 'R01239', 
        'GBP': 'R01035',
        'CNY': 'R01375'
    }
    
    hook = PostgresHook(postgres_conn_id='postgresql982')
    all_records = []
    
    for currency_name, currency_code in currencies.items():
        try:
            url = f"https://www.cbr.ru/scripts/XML_dynamic.asp?date_req1=01/01/2020&date_req2=24/11/2025&VAL_NM_RQ={currency_code}"
            
            logger.info(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ {currency_name}...")
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ XML
            records = parse_cbr_xml(response.content, currency_code)
            all_records.extend(records)
            
            logger.info(f"âœ… Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ {currency_name} Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹")
            
        except Exception as e:
            logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ {currency_name}: {e}")
            continue
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ²ÑĞµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ² Ğ±Ğ°Ğ·Ñƒ
    if all_records:
        insert_sql = """
        INSERT INTO analytics.currencies_history (currency, value, val_date)
        VALUES (%s, %s, %s)
        ON CONFLICT (currency, val_date) DO UPDATE SET
            value = EXCLUDED.value,
            sysdate = CURRENT_TIMESTAMP;
        """
        
        for record in all_records:
            hook.run(insert_sql, parameters=(
                record['currency'],
                record['value'], 
                record['val_date']
            ))
        
        logger.info(f"âœ… Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ {len(all_records)} Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹")
        return f"Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ {len(all_records)} Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹"
    
    return "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ"

def parse_daily_xml(xml_content):
    """ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾Ğ³Ğ¾ XML Ñ ĞºÑƒÑ€ÑĞ°Ğ¼Ğ¸ Ğ²Ğ°Ğ»ÑÑ‚"""
    try:
        root = ET.fromstring(xml_content)
        records = []
        
        # Ğ”Ğ°Ñ‚Ğ° Ğ¸Ğ· XML (Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Ğ´Ğ´.Ğ¼Ğ¼.Ğ³Ğ³Ğ³Ğ³)
        date_str = root.get('Date')
        val_date = datetime.strptime(date_str, '%d.%m.%Y').date()
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğµ Ğ²Ğ°Ğ»ÑÑ‚Ñ‹ Ğ¿Ğ¾ CharCode
        target_currencies = ['USD', 'EUR', 'GBP', 'CNY']
        
        for valute in root.findall('Valute'):
            char_code = valute.find('CharCode').text
            if char_code in target_currencies:
                value_str = valute.find('Value').text.replace(',', '.')
                value = float(value_str)
                
                records.append({
                    'currency': char_code,
                    'value': value,
                    'val_date': val_date
                })
        
        logger.info(f"âœ… Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ñ‹ ĞºÑƒÑ€ÑÑ‹ Ğ½Ğ° {val_date}: {len(records)} Ğ²Ğ°Ğ»ÑÑ‚")
        return records
        
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾Ğ³Ğ¾ XML: {e}")
        raise

def load_daily_data():
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ°"""
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ°ÑˆĞ½ÑÑ Ğ´Ğ°Ñ‚Ñƒ
    tomorrow = datetime.now() + timedelta(days=1)
    date_req = tomorrow.strftime('%d/%m/%Y')
    
    try:
        url = f"https://www.cbr.ru/scripts/XML_daily.asp?date_req={date_req}"
        
        logger.info(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° {date_req}...")
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ XML
        records = parse_daily_xml(response.content)
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ğ±Ğ°Ğ·Ñƒ
        if records:
            hook = PostgresHook(postgres_conn_id='postgresql982')
            
            insert_sql = """
            INSERT INTO analytics.currencies_history (currency, value, val_date)
            VALUES (%s, %s, %s)
            ON CONFLICT (currency, val_date) DO UPDATE SET
                value = EXCLUDED.value,
                sysdate = CURRENT_TIMESTAMP;
            """
            
            for record in records:
                hook.run(insert_sql, parameters=(
                    record['currency'],
                    record['value'],
                    record['val_date']
                ))
            
            currency_list = ', '.join([r['currency'] for r in records])
            logger.info(f"âœ… Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ñ‹Ğµ ĞºÑƒÑ€ÑÑ‹: {currency_list} Ğ½Ğ° {records[0]['val_date']}")
            return f"Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ ĞºÑƒÑ€ÑÑ‹: {currency_list}"
        
        return "ĞĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ"
        
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {e}")
        raise

def log_final_stats(**context):
    """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸"""
    hook = PostgresHook(postgres_conn_id='postgresql982')
    
    stats_sql = """
    SELECT 
        COUNT(*) as total_records,
        COUNT(DISTINCT currency) as currency_count,
        MIN(val_date) as earliest_date,
        MAX(val_date) as latest_date
    FROM analytics.currencies_history;
    """
    
    try:
        stats = hook.get_first(stats_sql)
        logger.info(f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Currencies History:")
        logger.info(f"   Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹: {stats[0]}")
        logger.info(f"   ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ°Ğ»ÑÑ‚: {stats[1]}")
        logger.info(f"   ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: {stats[2]} - {stats[3]}")
        
        return f"Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°: {stats[0]} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹, {stats[1]} Ğ²Ğ°Ğ»ÑÑ‚"
        
    except Exception as e:
        logger.warning(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ: {e}")
        return "Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°"

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ DAG Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼ Ğ² 19:00
default_args = {
    'owner': 'airflow',
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
    'start_date': datetime(2023, 1, 1),
}

with DAG(
    'cbr_currency_loader',
    default_args=default_args,
    description='Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ĞºÑƒÑ€ÑĞ¾Ğ² Ğ²Ğ°Ğ»ÑÑ‚ Ğ¦Ğ‘ Ğ Ğ¤ - Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸ ĞµĞ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ',
    # schedule=timedelta(minutes=30),
    schedule='0 19 * * *',  # â° Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ: Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾ Ğ² 19:00
    catchup=False,
    tags=['cbr', 'currency', 'analytics'],
    max_active_runs=1
) as dag:

    create_table_task = PythonOperator(
        task_id='create_currencies_table',
        python_callable=create_currencies_table,
    )

    check_first_run_task = PythonOperator(
        task_id='check_first_run',
        python_callable=check_if_first_run,
    )

    load_historical_data_task = PythonOperator(
        task_id='load_historical_data',
        python_callable=load_historical_data,
    )

    load_daily_data_task = PythonOperator(
        task_id='load_daily_data',
        python_callable=load_daily_data,
    )

    log_stats_task = PythonOperator(
        task_id='log_final_stats',
        python_callable=log_final_stats,
    )

    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ²ĞµÑ‚Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼
    create_table_task >> check_first_run_task >> [load_historical_data_task, load_daily_data_task]
    load_historical_data_task >> log_stats_task
    load_daily_data_task >> log_stats_task