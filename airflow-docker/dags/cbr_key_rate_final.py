# dags/cbr_key_rate_final.py
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from airflow.providers.standard.operators.empty import EmptyOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from datetime import datetime, timedelta
import requests
import xml.etree.ElementTree as ET
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

def load_data(**kwargs):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –∫–ª—é—á–µ–≤–æ–π —Å—Ç–∞–≤–∫–µ –¶–ë –†–§"""
    logger = logging.getLogger(__name__)
    
    try:
        # SOAP –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π —Å—Ç–∞–≤–∫–∏
        soap_request = '''<?xml version="1.0" encoding="utf-8"?>
<soap12:Envelope xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soap12="http://www.w3.org/2003/05/soap-envelope">
  <soap12:Body>
    <KeyRateXML xmlns="http://web.cbr.ru/">
      <fromDate>2020-01-01T00:00:00</fromDate>
      <ToDate>2025-11-22T23:59:59</ToDate>
    </KeyRateXML>
  </soap12:Body>
</soap12:Envelope>'''
        
        headers = {'Content-Type': 'application/soap+xml; charset=utf-8'}
        
        logger.info("üì° –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –¶–ë –†–§...")
        response = requests.post(
            "https://www.cbr.ru/DailyInfoWebServ/DailyInfo.asmx",
            data=soap_request,
            headers=headers,
            timeout=30
        )
        
        logger.info(f"‚úÖ –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ. –°—Ç–∞—Ç—É—Å: {response.status_code}")
        logger.info(f"üìÑ –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        root = ET.fromstring(response.text)
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ - –∏—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞–ø—Ä—è–º—É—é
        logger.info("üîç –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã KR –Ω–∞–ø—Ä—è–º—É—é...")
        
        rates_data = []
        
        # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã KR –≤ –ª—é–±–æ–º –Ω–µ–π–º—Å–ø–µ–π—Å–µ
        for elem in root.iter():
            # –£–±–∏—Ä–∞–µ–º –Ω–µ–π–º—Å–ø–µ–π—Å –∏–∑ —Ç–µ–≥–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            tag_clean = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
            
            if tag_clean == 'KR':
                # –ù–∞—à–ª–∏ —ç–ª–µ–º–µ–Ω—Ç KR, –∏—â–µ–º –≤–Ω—É—Ç—Ä–∏ –Ω–µ–≥–æ DT –∏ Rate
                kr_data = {}
                for child in elem:
                    child_tag = child.tag.split('}')[-1] if '}' in child.tag else child.tag
                    if child_tag == 'DT':
                        kr_data['date'] = child.text
                    elif child_tag == 'Rate':
                        kr_data['rate'] = float(child.text) if child.text else None
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –æ–±–µ –¥–∞—Ç—ã, –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if 'date' in kr_data and 'rate' in kr_data:
                    rates_data.append(kr_data)
        
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(rates_data)} –∑–∞–ø–∏—Å–µ–π KR")
        
        if rates_data:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–æ—Ç –Ω–æ–≤—ã—Ö –∫ —Å—Ç–∞—Ä—ã–º)
            rates_data.sort(key=lambda x: x['date'], reverse=True)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
            for i, item in enumerate(rates_data[:5]):
                logger.info(f"üìà –ü—Ä–∏–º–µ—Ä {i+1}: {item['date']} - {item['rate']}%")
            
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(rates_data)} –∑–∞–ø–∏—Å–µ–π")
            
            # –ü–µ—Ä–µ–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ XCom
            kwargs['ti'].xcom_push(key='key_rates_data', value=rates_data)
            return rates_data
        else:
            logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ –æ—Ç–≤–µ—Ç–µ")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
            logger.info("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã XML:")
            unique_tags = set()
            for elem in root.iter():
                tag_clean = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
                unique_tags.add(tag_clean)
                if len(unique_tags) > 20:  # –û–≥—Ä–∞–Ω–∏—á–∏–º –≤—ã–≤–æ–¥
                    break
            
            logger.info(f"üîç –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏ –≤ –æ—Ç–≤–µ—Ç–µ: {sorted(unique_tags)}")
            
            return []
        
    except ET.ParseError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
        if 'response' in locals():
            logger.info(f"üìÑ –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response.text[:500]}")
        return []
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return []
    
def transform_data(**kwargs):
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ XCom
    ti = kwargs['ti']
    rates_data = ti.xcom_pull(task_ids='load_data', key='key_rates_data')
    
    if not rates_data:
        logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        return []
    
    logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(rates_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    
    # –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è - –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ —Å –≥–æ–¥–æ–º
    transformed_data = []
    for item in rates_data:
        try:
            transformed_item = item.copy()
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥ –∏–∑ –¥–∞—Ç—ã (—Ñ–æ—Ä–º–∞—Ç: 2023-01-15T00:00:00)
            if item['date'] and 'T' in item['date']:
                year = item['date'].split('T')[0].split('-')[0]
                transformed_item['year'] = int(year)
            else:
                transformed_item['year'] = None
            
            transformed_data.append(transformed_item)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–∏ {item}: {e}")
            continue
    
    logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ {len(transformed_data)} –∑–∞–ø–∏—Å–µ–π")
    
    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    for i, item in enumerate(transformed_data[:3]):
        logger.info(f"üîÑ –ü—Ä–∏–º–µ—Ä {i+1}: {item}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ XCom
    kwargs['ti'].xcom_push(key='transformed_rates_data', value=transformed_data)
    return transformed_data

def load_to_postgres(**kwargs):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL"""
    logger.info("üíæ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL...")
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ XCom
    ti = kwargs['ti']
    transformed_data = ti.xcom_pull(task_ids='transform_data', key='transformed_rates_data')
    
    if not transformed_data:
        logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î")
        return
    
    logger.info(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º {len(transformed_data)} –∑–∞–ø–∏—Å–µ–π –≤ –ë–î")
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ PostgreSQL
        hook = PostgresHook(postgres_conn_id='postgresql982')
        conn = hook.get_conn()
        cursor = conn.cursor()
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        insert_sql = """
        INSERT INTO analytics.cb_bid (rate_date, rate_value, year)
        VALUES (%s, %s, %s)
        ON CONFLICT (rate_date) DO UPDATE SET
            rate_value = EXCLUDED.rate_value,
            year = EXCLUDED.year,
            updated_at = CURRENT_TIMESTAMP
        """
        
        for item in transformed_data:
            cursor.execute(insert_sql, (
                item['date'].split('T')[0] if 'T' in item['date'] else item['date'],
                item['rate'],
                item.get('year')
            ))
        
        conn.commit()
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(transformed_data)} –∑–∞–ø–∏—Å–µ–π –≤ PostgreSQL")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤ PostgreSQL: {e}")
        raise
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ DAG
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'cbr_key_rate_final',
    default_args=default_args,
    description='–ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª—é—á–µ–≤–æ–π —Å—Ç–∞–≤–∫–∏ –¶–ë –†–§',
    schedule='0 12 * * *',  # –ï–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 12:00 - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ schedule
    start_date=datetime(2023, 1, 1),
    catchup=False,
    tags=['cbr', 'key_rate', 'finance'],
) as dag:

    start = EmptyOperator(task_id='start')
    
    create_table = PostgresOperator(
        task_id='create_table',
        postgres_conn_id='postgresql982',
        sql="""
        CREATE TABLE IF NOT EXISTS analytics.cb_bid (
            id SERIAL PRIMARY KEY,
            rate_date DATE UNIQUE NOT NULL,
            rate_value DECIMAL(8,4) NOT NULL,
            year INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        CREATE INDEX IF NOT EXISTS idx_an_cbr_key_rates_date ON analytics.cb_bid(rate_date);
        CREATE INDEX IF NOT EXISTS idx_an_cbr_key_rates_year ON analytics.cb_bid(year);
        """
    )
    
    load_data_task = PythonOperator(
        task_id='load_data',
        python_callable=load_data,
    )
    
    transform_data_task = PythonOperator(
        task_id='transform_data',
        python_callable=transform_data,
    )
    
    load_to_postgres_task = PythonOperator(
        task_id='load_to_postgres',
        python_callable=load_to_postgres,
    )
    
    end = EmptyOperator(task_id='end')

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    start >> create_table >> load_data_task >> transform_data_task >> load_to_postgres_task >> end