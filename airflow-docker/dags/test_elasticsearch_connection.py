# dags/test_elasticsearch_connection.py
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from airflow.providers.standard.operators.empty import EmptyOperator
from airflow.hooks.base import BaseHook
from datetime import datetime
import logging
import requests
import json

logger = logging.getLogger(__name__)

def test_es_connection_simple(**kwargs):
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº ElasticSearch Ñ‡ĞµÑ€ĞµĞ· REST API"""
    logger.info("ğŸ” ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº ElasticSearch...")
    
    try:
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Airflow
        connection = BaseHook.get_connection('elasticsearch_default')
        
        logger.info("âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ 'elasticsearch_default'")
        logger.info(f"ğŸ“‹ ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ:")
        logger.info(f"   - Host: {connection.host}")
        logger.info(f"   - Port: {connection.port}")
        logger.info(f"   - Login: {connection.login}")
        logger.info(f"   - Schema: {connection.schema}")
        logger.info(f"   - Extra: {connection.extra}")
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ URL Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
        if connection.port:
            es_url = f"{connection.host}:{connection.port}"
        else:
            es_url = connection.host
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑÑ…ĞµĞ¼Ñƒ ĞµÑĞ»Ğ¸ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚
        if not es_url.startswith(('http://', 'https://')):
            es_url = f"http://{es_url}"
        
        logger.info(f"ğŸŒ URL ElasticSearch: {es_url}")
        
        # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
        auth = None
        if connection.login and connection.password:
            auth = (connection.login, connection.password)
            logger.info("ğŸ” Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²ÑƒÑ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ")
        
        # Ğ¢ĞµÑÑ‚ 1: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
        logger.info("ğŸ”„ Ğ¢ĞµÑÑ‚ 1: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°...")
        health_url = f"{es_url}/_cluster/health"
        
        response = requests.get(health_url, auth=auth, timeout=30)
        
        if response.status_code == 200:
            health_data = response.json()
            logger.info("âœ… ĞšĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½")
            logger.info(f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°: {health_data.get('status', 'unknown')}")
            logger.info(f"ğŸ·ï¸  Ğ˜Ğ¼Ñ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°: {health_data.get('cluster_name', 'unknown')}")
        else:
            logger.error(f"âŒ ĞšĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½. HTTP {response.status_code}: {response.text}")
            return False
        
        # Ğ¢ĞµÑÑ‚ 2: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ ÑƒĞ·Ğ»Ğµ
        logger.info("ğŸ”„ Ğ¢ĞµÑÑ‚ 2: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ ÑƒĞ·Ğ»Ğµ...")
        info_url = f"{es_url}/"
        
        response = requests.get(info_url, auth=auth, timeout=30)
        
        if response.status_code == 200:
            info_data = response.json()
            logger.info("âœ… Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑƒĞ·Ğ»Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ°")
            logger.info(f"ğŸ”¢ Ğ’ĞµÑ€ÑĞ¸Ñ Elasticsearch: {info_data['version']['number']}")
            logger.info(f"ğŸ“› Ğ˜Ğ¼Ñ ÑƒĞ·Ğ»Ğ°: {info_data['name']}")
        else:
            logger.error(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑƒĞ·Ğ»Ğµ. HTTP {response.status_code}")
            return False
        
        # Ğ¢ĞµÑÑ‚ 3: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²
        logger.info("ğŸ”„ Ğ¢ĞµÑÑ‚ 3: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²...")
        indices_url = f"{es_url}/_cat/indices?format=json&s=index"
        
        response = requests.get(indices_url, auth=auth, timeout=30)
        
        if response.status_code == 200:
            indices = response.json()
            logger.info(f"ğŸ“Š ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²: {len(indices)}")
            for idx in indices[:5]:  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 5 Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²
                logger.info(f"   - {idx['index']}: {idx.get('docs.count', 'N/A')} Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
        else:
            logger.warning(f"âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ². HTTP {response.status_code}")
        
        # Ğ¢ĞµÑÑ‚ 4: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°
        test_index = "test_airflow_connection"
        logger.info(f"ğŸ”„ Ğ¢ĞµÑÑ‚ 4: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ğ´ĞµĞºÑĞ° '{test_index}'...")
        
        create_index_url = f"{es_url}/{test_index}"
        
        index_settings = {
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 0
            },
            "mappings": {
                "properties": {
                    "test_field": {"type": "text"},
                    "timestamp": {"type": "date"},
                    "dag_name": {"type": "keyword"}
                }
            }
        }
        
        response = requests.put(
            create_index_url,
            json=index_settings,
            auth=auth,
            timeout=30
        )
        
        if response.status_code in [200, 201]:
            logger.info(f"âœ… Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ½Ğ´ĞµĞºÑ '{test_index}' ÑĞ¾Ğ·Ğ´Ğ°Ğ½")
        elif response.status_code == 400 and "already_exists" in response.text:
            logger.info(f"â„¹ï¸ Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ½Ğ´ĞµĞºÑ '{test_index}' ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚")
        else:
            logger.error(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¸Ğ½Ğ´ĞµĞºÑ. HTTP {response.status_code}: {response.text}")
            return False
        
        # Ğ¢ĞµÑÑ‚ 5: Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°
        logger.info("ğŸ”„ Ğ¢ĞµÑÑ‚ 5: Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°...")
        doc_url = f"{es_url}/{test_index}/_doc"
        
        test_doc = {
            "test_field": "Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚ Airflow DAG",
            "timestamp": datetime.now().isoformat(),
            "dag_name": "test_elasticsearch_connection",
            "connection_id": "elasticsearch_default"
        }
        
        response = requests.post(
            doc_url,
            json=test_doc,
            auth=auth,
            timeout=30
        )
        
        if response.status_code in [200, 201]:
            doc_data = response.json()
            doc_id = doc_data['_id']
            logger.info(f"âœ… Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½ Ñ ID: {doc_id}")
        else:
            logger.error(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚. HTTP {response.status_code}: {response.text}")
            return False
        
        # Ğ¢ĞµÑÑ‚ 6: Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°
        logger.info("ğŸ”„ Ğ¢ĞµÑÑ‚ 6: Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°...")
        get_doc_url = f"{es_url}/{test_index}/_doc/{doc_id}"
        
        response = requests.get(get_doc_url, auth=auth, timeout=30)
        
        if response.status_code == 200:
            doc_data = response.json()
            logger.info(f"âœ… Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ½: {doc_data['_source']['test_field']}")
        else:
            logger.error(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚. HTTP {response.status_code}")
            return False
        
        # Ğ¢ĞµÑÑ‚ 7: ĞŸĞ¾Ğ¸ÑĞº Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°
        logger.info("ğŸ”„ Ğ¢ĞµÑÑ‚ 7: ĞŸĞ¾Ğ¸ÑĞº Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°...")
        search_url = f"{es_url}/{test_index}/_search"
        
        search_query = {
            "query": {
                "match": {
                    "test_field": "Airflow"
                }
            }
        }
        
        response = requests.post(
            search_url,
            json=search_query,
            auth=auth,
            timeout=30
        )
        
        if response.status_code == 200:
            search_data = response.json()
            hits = search_data['hits']['total']['value']
            logger.info(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {hits}")
        else:
            logger.error(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ¸ÑĞº. HTTP {response.status_code}")
            return False
        
        # Ğ¢ĞµÑÑ‚ 8: Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°
        logger.info("ğŸ”„ Ğ¢ĞµÑÑ‚ 8: Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°...")
        delete_index_url = f"{es_url}/{test_index}"
        
        response = requests.delete(delete_index_url, auth=auth, timeout=30)
        
        if response.status_code in [200, 201]:
            logger.info("âœ… Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ½Ğ´ĞµĞºÑ ÑƒĞ´Ğ°Ğ»ĞµĞ½")
        else:
            logger.warning(f"âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ğ´ĞµĞºÑ. HTTP {response.status_code}")
        
        # Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚
        logger.info("ğŸ‰ Ğ’ÑĞµ Ñ‚ĞµÑÑ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ¹Ğ´ĞµĞ½Ñ‹ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!")
        logger.info("âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº ElasticSearch Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾")
        
        result = {
            "status": "success",
            "cluster_name": health_data.get('cluster_name', 'unknown'),
            "version": info_data['version']['number'],
            "tests_passed": 8,
            "es_url": es_url
        }
        
        kwargs['ti'].xcom_push(key='test_result', value=result)
        return result
        
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ: {e}")
        
        import traceback
        logger.error(f"ğŸ” Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸: {traceback.format_exc()}")
        
        result = {
            "status": "failed",
            "error": str(e),
            "tests_passed": 0
        }
        
        kwargs['ti'].xcom_push(key='test_result', value=result)
        return result

def generate_report(**kwargs):
    """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸"""
    ti = kwargs['ti']
    test_result = ti.xcom_pull(task_ids='test_es_connection', key='test_result')
    
    logger.info("ğŸ“Š ===== ĞĞ¢Ğ§Ğ•Ğ¢ Ğ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ˜ ELASTICSEARCH =====")
    
    if test_result and test_result.get('status') == 'success':
        logger.info("ğŸ‰ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: Ğ£Ğ¡ĞŸĞ•Ğ¥")
        logger.info(f"ğŸ·ï¸  Ğ˜Ğ¼Ñ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°: {test_result.get('cluster_name')}")
        logger.info(f"ğŸ”¢ Ğ’ĞµÑ€ÑĞ¸Ñ: {test_result.get('version')}")
        logger.info(f"ğŸŒ URL: {test_result.get('es_url')}")
        logger.info(f"âœ… ĞŸÑ€Ğ¾Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²: {test_result.get('tests_passed')}")
        logger.info("ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸: ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¾ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾")
    else:
        logger.error("ğŸ’¥ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: ĞŸĞ ĞĞ’ĞĞ›")
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {test_result.get('error', 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°')}")
        logger.info("ğŸ”§ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ² Airflow UI")
        
        logger.info("""
ğŸ”§ ĞšĞĞš ĞĞĞ¡Ğ¢Ğ ĞĞ˜Ğ¢Ğ¬ ĞŸĞĞ”ĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•:
1. ĞÑ‚ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ Airflow UI â†’ Admin â†’ Connections
2. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ:
   - Conn Id: elasticsearch_default
   - Conn Type: HTTP (Ğ¸Ğ»Ğ¸ Elasticsearch ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾)
   - Host: Ğ²Ğ°Ñˆ ES Ñ…Ğ¾ÑÑ‚ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: http://elasticsearch:9200 Ğ¸Ğ»Ğ¸ localhost:9200)
   - Port: 9200
   - Extra: {{"timeout": 30}}
3. Ğ”Ğ»Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ ÑƒĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Login/Password ĞµÑĞ»Ğ¸ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ
4. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚Ğµ Ğ¸ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ DAG
        """)

with DAG(
    'test_elasticsearch_connection',
    description='Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº ElasticSearch Ñ‡ĞµÑ€ĞµĞ· REST API',
    schedule=None,  # Ğ ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['test', 'elasticsearch', 'connection', 'debug'],
    default_args={
        'owner': 'airflow',
        'retries': 0,
    }
) as dag:

    start = EmptyOperator(task_id='start')
    
    test_connection_task = PythonOperator(
        task_id='test_es_connection',
        python_callable=test_es_connection_simple,
    )
    
    generate_report_task = PythonOperator(
        task_id='generate_report',
        python_callable=generate_report,
    )
    
    end = EmptyOperator(task_id='end')

    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
    start >> test_connection_task >> generate_report_task >> end